* 行列相乘得行列,内相同,外大小  
* 每层权重个数为`(此层神经元个数)x(上层神经元个数+1)`
>每个都给我,偏置不能少  
>要想知总数,乘以我数目  

* 神经网络反向传播算法理解说明
>* 最后一层计算结果并得到costfunction,得到误差,最后的costfunction虽然只用了上一层的结果和权重进行计算,但是上一层的结果又是上上层得来的,因此整个costfunction实际还是所有层上所有权重的函数,因此正则化项依然包含所有权重项  
>* 按道理说,这时候计算偏导,梯度下降依然是行的通的,但是由于一层接一层,复合函数嵌套复合函数,所以整体的形式必然非常麻烦,由此还是把每个unit的复合函数当成整体,构建一种**反向传播算法**.这时候各个权重的偏导项又变得简洁统一,方便程序计算  
>* 不用算也可以想到,这时候反向传播计算偏导虽然形式变得简洁,但是必然会用到上一层(其实是下一层,不过这里变成反向,所以说成上一层)的结果,不然数据就失去关联性了,不符合逻辑  
>* 最后根据反向传播计算出的每个偏导更新各个权重,至此,算法能够一直迭代

* 神经网络初始权重随机值在正负根号下6除以前后神经元数目之和之间随机比较好,,此时权重不能再像逻辑回归一样都初始为0,因为这样的话会使得反向传播时各权重梯度下降一致,大大降低网络的工作性能